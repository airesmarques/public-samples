{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been tested for Python3.9\n",
    "\n",
    "Install the packages\n",
    "Make sure you have a credentials file json in the current folder\n",
    "Adjust the script to provide the .json file, a local file with an image, and a link to a an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install types-chardet\n",
    "%pip install google-cloud-vision\n",
    "%pip install pytest\n",
    "%pip install pytest-env\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_SA_CREDENTIALS_FILE_NAME=\"your credentials file name.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses a local file to detect if there is a person or not in the image\n",
    "\n",
    "\n",
    "def person_detection_file(filename: str) -> bool:  # change return type to bool\n",
    "    \"\"\"Provides a quick start example for Cloud Vision.\"\"\"\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        os.getenv(\"GCP_SA_CREDENTIALS_FILE_NAME\"))\n",
    "\n",
    "    #credentials_json = json.loads(os.getenv(\"GCP_SA_VISION_API_JSON\"))\n",
    "    #credentials = service_account.Credentials.from_service_account_info(credentials_json)\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "    # The name of the image file to annotate\n",
    "    file_name = os.path.abspath(filename)\n",
    "\n",
    "    # Loads the image into memory\n",
    "    with open(file_name, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Performs object localization on the image file\n",
    "    response = client.object_localization(image=image)\n",
    "    objects = response.localized_object_annotations\n",
    "\n",
    "    person_detected = False\n",
    "    for object_ in objects:\n",
    "        if object_.name.lower() == 'person':\n",
    "            person_detected = True\n",
    "            break\n",
    "\n",
    "    return person_detected \n",
    "\n",
    "res1 = person_detection_file(\"local file name of your choice.jpg\")\n",
    "print (res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses a remote to detect if there is a person or not in the image\n",
    "\n",
    "\n",
    "def person_detection_url(image_url: str) -> bool:\n",
    "    \"\"\"Provides a quick start example for Cloud Vision.\"\"\"\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        \"yimai-devtest-sa.json\")\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "    # Creates a vision.Image object with the image URL\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = image_url\n",
    "\n",
    "    # Performs object localization on the image file\n",
    "    response = client.object_localization(image=image)\n",
    "    objects = response.localized_object_annotations\n",
    "\n",
    "    person_detected = False\n",
    "    for object_ in objects:\n",
    "        if object_.name.lower() == 'person':\n",
    "            person_detected = True\n",
    "            break\n",
    "\n",
    "    return person_detected\n",
    "\n",
    "\n",
    "\n",
    "file_with_sas = \"path to a public file or azure blob with sas\"\n",
    "res2 = person_detection_url(file_with_sas)\n",
    "print(res2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
